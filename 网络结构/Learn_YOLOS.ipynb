{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 网络结构\n",
    "\n",
    "YOLOS\n",
    "![image-20230407上午101700351](../配图/Transformer家族.assets/image-20230407上午101700351.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ViT\n",
    "<img src=\"../配图/Transformer家族.assets/image-20220812下午35357981.png\" alt=\"image-20220812下午35357981\" style=\"zoom: 67%;\" />\n",
    "\n",
    "yolos 的结构是在 ViT 的基础上做了改变，从图中可以看出主干网络结构是和 vit 一致的，只不过 yolos 作为检测任务，他在 vit 的基础上concat了 100 个 det token，\n",
    "\n",
    "所以进入 encode 的输入是:\n",
    "$$\n",
    "z_0 = [x_{PATCH}^1 E,x_{PATCH}^2 E,...x_{PATCH}^N E,x_{DET}^{100}]+P\n",
    "$$\n",
    "其中 $x_{PATCH}^i E$ 就是普通 vit 的输入，$x_{DET}^{j}$ 就是100 个可以学习的 det，$P\\in (N+100,D)$ 是增加的位置编码，来保留输入的位置信息。\n",
    "\n",
    "\n",
    "\n",
    "模型的特征的输出依旧是$[1,N+100,D]$的尺寸\n",
    "\n",
    "```Python\n",
    "return x[:, -self.det_token_num:, :]\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "det 是一个 1,100,768 的尺寸，它是随机初始化的，以避免2D结构的归纳偏置和标签分配过程中注入任务的先验知识。\n",
    "\n",
    "```Python\n",
    "self.det_token = nn.Parameter(torch.zeros(1, det_token_num, self.embed_dim))   # 1,100,768\n",
    "self.det_token = trunc_normal_(self.det_token, std=.02)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "将这个特征输出进入两个参数不共享的 MLP。\n",
    "\n",
    "```Python\n",
    "self.class_embed = MLP(hidden_dim,hidden_dim,output_dim=num_classes+ 1,num_layers=3)\n",
    "\n",
    "self.bbox_embed = MLP(hidden_dim,hidden_dim,output_dim=4,num_layers=3)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MLP包含两个隐藏层，中间带有ReLU，每层都不会改变尺寸。\n",
    "\n",
    "```Python\n",
    "class MLP(nn.Module):\n",
    "    \"\"\" Very simple multi-layer perceptron (also called FFN)\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        h = [hidden_dim] * (num_layers - 1)\n",
    "        self.layers = nn.ModuleList(nn.Linear(n, k) for n, k in zip([input_dim] + h, h + [output_dim]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            # 除了最后一层，每层都有 ReLU\n",
    "            x = F.relu(layer(x)) if i < self.num_layers - 1 else layer(x)\n",
    "        return x\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "检测的输出就是 MLP 输出结果的 sigmoid，模型最终就输出类别和检测\n",
    "\n",
    "```Python\n",
    "outputs_class = self.class_embed(x)\n",
    "outputs_coord = self.bbox_embed(x).sigmoid()\n",
    "out = {'pred_logits': outputs_class, 'pred_boxes': outputs_coord}\n",
    "        return out\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 微调操作\n",
    "\n",
    "所有参数都从ImageNet-1k预训练的权重初始化，**除了两个MLP头以及100个随机初始化的det token。**\n",
    "\n",
    "\n",
    "\n",
    "模型使用了 imagenet 进行了预训练，随后使用了 coco 数据集进行微调，但是coco 数据集的分辨率比 imagenet 更大，所以还是保持了 16*16 个 patch不变，但是这样的尺寸就会变大，**所以使用 2d 插值来讲位置编码变得和输入尺寸一样大。**\n",
    "\n",
    "\n",
    "\n",
    "这样 N 变大了，但是768 的尺寸不变，依旧可以将 patch token，det token，cls 拼接在一起。\n",
    "\n",
    "```Python\n",
    "patch_pos_embed # 1,196,768\n",
    "img_size = [800,1344]\n",
    "\n",
    "patch_pos_embed = patch_pos_embed.transpose(1,2)  # 1,768,196\n",
    "B, E, Q = patch_pos_embed.shape # 1 768 196\n",
    "P_H, P_W = self.img_size[0] // self.patch_size, self.img_size[1] // self.patch_size  # 14,14\n",
    "\n",
    "patch_pos_embed = patch_pos_embed.view(B, E, P_H, P_W) # 1,768,14,14\n",
    "H, W = img_size\n",
    "new_P_H, new_P_W = H//self.patch_size, W//self.patch_size # 50,84\n",
    "\n",
    "# 双线性插值\n",
    "patch_pos_embed = nn.functional.interpolate(patch_pos_embed, size=(new_P_H,new_P_W), mode='bicubic', align_corners=False) # 1,768,50,48\n",
    "\n",
    "\n",
    "patch_pos_embed = patch_pos_embed.flatten(2).transpose(1, 2) # 1,4200,768\n",
    "\n",
    "```\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
